{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-d0d7acd7e5d4>:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask.diagnostics import progress\n",
    "from tqdm.autonotebook import tqdm \n",
    "import intake\n",
    "import fsspec\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ssp370SST-ssp126Lu',\n",
       " 'ssp370SST-lowNTCF',\n",
       " 'ssp370SST-lowCH4',\n",
       " 'ssp370-lowNTCF',\n",
       " 'ssp370pdSST',\n",
       " 'ssp370SST',\n",
       " 'ssp245',\n",
       " 'esm-ssp585',\n",
       " 'ssp126-ssp370Lu',\n",
       " 'ssp370-ssp126Lu',\n",
       " 'esm-ssp585-ssp126Lu',\n",
       " 'ssp585',\n",
       " 'ssp370',\n",
       " 'ssp126',\n",
       " 'ssp119',\n",
       " 'ssp245-GHG',\n",
       " 'ssp245-nat',\n",
       " 'ssp434',\n",
       " 'ssp460',\n",
       " 'ssp534-over',\n",
       " 'ssp245-aer',\n",
       " 'ssp245-stratO3',\n",
       " 'ssp245-cov-fossil',\n",
       " 'ssp245-covid',\n",
       " 'ssp245-cov-strgreen',\n",
       " 'ssp245-cov-modgreen',\n",
       " 'ssp585-bgc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[eid for eid in col.df['experiment_id'].unique() if 'ssp' in eid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>table_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACCESS-CM2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCESS-ESM1-5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWI-CM-1-1-MR</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCC-CSM2-MR</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CESM2-WACCM</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMCC-CM2-SR5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMCC-ESM2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CanESM5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC-Earth3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC-Earth3-Veg</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC-Earth3-Veg-LR</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGOALS-g3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFDL-ESM4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IITM-ESM</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INM-CM4-8</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INM-CM5-0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPSL-CM6A-LR</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KACE-1-0-G</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIOST-ESM</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIROC6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPI-ESM1-2-HR</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPI-ESM1-2-LR</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI-ESM2-0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NESM3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorESM2-LM</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorESM2-MM</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  experiment_id  variable_id  table_id\n",
       "source_id                                             \n",
       "ACCESS-CM2                    4            1         1\n",
       "ACCESS-ESM1-5                 4            1         1\n",
       "AWI-CM-1-1-MR                 4            1         1\n",
       "BCC-CSM2-MR                   4            1         1\n",
       "CESM2-WACCM                   4            1         1\n",
       "CMCC-CM2-SR5                  4            1         1\n",
       "CMCC-ESM2                     4            1         1\n",
       "CanESM5                       4            1         1\n",
       "EC-Earth3                     4            1         1\n",
       "EC-Earth3-Veg                 4            1         1\n",
       "EC-Earth3-Veg-LR              4            1         1\n",
       "FGOALS-g3                     4            1         1\n",
       "GFDL-ESM4                     4            1         1\n",
       "IITM-ESM                      4            1         1\n",
       "INM-CM4-8                     4            1         1\n",
       "INM-CM5-0                     4            1         1\n",
       "IPSL-CM6A-LR                  4            1         1\n",
       "KACE-1-0-G                    4            1         1\n",
       "KIOST-ESM                     4            1         1\n",
       "MIROC6                        4            1         1\n",
       "MPI-ESM1-2-HR                 4            1         1\n",
       "MPI-ESM1-2-LR                 4            1         1\n",
       "MRI-ESM2-0                    4            1         1\n",
       "NESM3                         4            1         1\n",
       "NorESM2-LM                    4            1         1\n",
       "NorESM2-MM                    4            1         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is currently a significant amount of data for these runs\n",
    "#expts = ['historical', 'ssp245', 'ssp585']\n",
    "expts = ['historical','ssp126','ssp245','ssp585']\n",
    "query = dict(\n",
    "    experiment_id=expts,\n",
    "    table_id='day',                           \n",
    "    variable_id=['tas'],\n",
    "    member_id = 'r1i1p1f1',                     \n",
    ")\n",
    "\n",
    "col_subset = col.search(require_all_on=[\"source_id\"], **query)\n",
    "col_subset.df.groupby(\"source_id\")[\n",
    "    [\"experiment_id\", \"variable_id\", \"table_id\"]\n",
    "].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = intake.open_esm_datastore('/Volumes/Transcend/tas_Amon_CAS-ESM2-0_ssp245_r1i1p1f1_gn_201501-210012.nc')\n",
    "def drop_all_bounds(ds):\n",
    "    drop_vars = [vname for vname in ds.coords\n",
    "                 if (('_bounds') in vname ) or ('_bnds') in vname]\n",
    "    return ds.drop(drop_vars)\n",
    "\n",
    "def open_dset(df):\n",
    "    assert len(df) == 1\n",
    "    ds = xr.open_zarr(fsspec.get_mapper(df.zstore.values[0]), consolidated=True)\n",
    "    return drop_all_bounds(ds)\n",
    "\n",
    "def open_delayed(df):\n",
    "    return dask.delayed(open_dset)(df)\n",
    "\n",
    "from collections import defaultdict\n",
    "dsets = defaultdict(dict) \n",
    "\n",
    "for group, df in col_subset.df.groupby(by=['source_id', 'experiment_id']):\n",
    "    dsets[group[0]][group[1]] = open_delayed(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/numpy/core/_asarray.py:102: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/numpy/core/_asarray.py:102: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/xarray/coding/times.py:527: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/numpy/core/_asarray.py:102: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/home/lulur/.conda/envs/cicoes39/lib/python3.9/site-packages/numpy/core/_asarray.py:102: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "dsets_ = dask.compute(dict(dsets))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate global means\n",
    "\n",
    "def get_lat_name(ds):\n",
    "    for lat_name in ['lat', 'latitude']:\n",
    "        if lat_name in ds.coords:\n",
    "            return lat_name\n",
    "    raise RuntimeError(\"Couldn't find a latitude coordinate\")\n",
    "\n",
    "def global_mean(ds):\n",
    "    lat = ds[get_lat_name(ds)]\n",
    "    weight = np.cos(np.deg2rad(lat))\n",
    "    weight /= weight.mean()\n",
    "    other_dims = set(ds.dims) - {'time'}\n",
    "    return (ds * weight).mean(other_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in tqdm(dsets_.items()):\n",
    "\n",
    "    # Check for any missing experiments that we expect\n",
    "    expt_dsets = v.values()\n",
    "    if any([d is None for d in expt_dsets]):\n",
    "        print(f\"Missing experiment for {k}\")\n",
    "        continue\n",
    "\n",
    "    climatology = v['historical'].sel(time=slice('1981-01-01', '2010-12-31')).groupby('time.month').mean('time')\n",
    "\n",
    "    for i in v:\n",
    "        if i == 'historical':\n",
    "            # When working with daily data, it's very easy for objects to run your computer out of memory, so we shorten historical runs because to the date range we need.\n",
    "            anomaly = v[i].sel(time=slice('1981-01-01', '2010-12-31')).groupby('time.month') - climatology\n",
    "        else:\n",
    "            anomaly = v[i].groupby('time.month') - climatology\n",
    "        # Because these files are too large to store in memory, we use the option compute=False to create a dask delayed object and then compute it later.\n",
    "        # Remember to change the file location to the relevant folder.\n",
    "        delayed_obj = anomaly.to_netcdf(path=f\"/nobackup/users/lulur/tas-anomaly_{k}_{i}.nc\", mode='w', compute=False, engine='netcdf4', format='NETCDF4')\n",
    "        print(f\"writing data to /nobackup/users/lulur/tas-anomaly_{k}_{i}.nc\")\n",
    "\n",
    "        with progress.ProgressBar():\n",
    "            results = delayed_obj.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing data to /nobackup/users/lulur/tas-anomaly_ACCESS-ESM1-5_ssp126.nc\n",
      "[######################################  ] | 95% Completed |  2min 54.7s"
     ]
    }
   ],
   "source": [
    "#for a SPECIFIC model, use the cell below:\n",
    "# Check for any missing experiments that we expect\n",
    "models = ['ACCESS-ESM1-5','NorESM2-LM','NorESM2-MM']\n",
    "for k in models:\n",
    "#k = 'ACCESS-WACCM'\n",
    "    v = dsets_[k]\n",
    "    expt_dsets = v.values()\n",
    "    #if any([d is None for d in expt_dsets]):\n",
    "        #print(f\"Missing experiment for {k}\")\n",
    "        #continue\n",
    "\n",
    "    climatology = v['historical'].sel(time=slice('1981-01-01', '2010-12-31')).groupby('time.dayofyear').mean('time')\n",
    "\n",
    "    for i in v:\n",
    "        if i == 'historical':\n",
    "            # When working with daily data, it's very easy for objects to run your computer out of memory, so we shorten historical runs because to the date range we need.\n",
    "            anomaly = v[i].sel(time=slice('1981-01-01', '2010-12-31')).groupby('time.dayofyear') - climatology\n",
    "        else:\n",
    "            anomaly = v[i].groupby('time.dayofyear') - climatology\n",
    "        # Because these files are too large to store in memory, we use the option compute=False to create a dask delayed object and then compute it later.\n",
    "        # Remember to change the file location to the relevant folder.\n",
    "            delayed_obj = anomaly.to_netcdf(path=f\"/nobackup/users/lulur/tas-anomaly_{k}_{i}.nc\", mode='w', compute=False, engine='netcdf4', format='NETCDF4')\n",
    "            print(f\"writing data to /nobackup/users/lulur/tas-anomaly_{k}_{i}.nc\")\n",
    "\n",
    "            with progress.ProgressBar():\n",
    "                results = delayed_obj.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_da = xr.DataArray(expts, dims='experiment_id', name='experiment_id',\n",
    "                        coords={'experiment_id': expts})\n",
    "\n",
    "dsets_aligned = {}\n",
    "\n",
    "for k, v in tqdm(dsets_.items()):\n",
    "    expt_dsets = v.values()\n",
    "    if any([d is None for d in expt_dsets]):\n",
    "        print(f\"Missing experiment for {k}\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    print(type(v[expt]) for expt in expts)\n",
    "    for ds in expt_dsets:\n",
    "        #ds.coords['year'] = ds.time.dt.year\n",
    "        #ds.coords['month']=ds.time.dt.month\n",
    "        #ds.coords['rawday'] = cftime.date2num\n",
    "        ds.coords['rawmonth']=ds.time.dt.month+(ds.time.dt.year-1850)*12\n",
    "        #print(ds.coords)\n",
    "    # workaround for\n",
    "    # https://github.com/pydata/xarray/issues/2237#issuecomment-620961663\n",
    "    dsets_mon_mean = [v[expt].pipe(global_mean)\n",
    "                             .swap_dims({'time': 'rawmonth'})\n",
    "                             .drop('time')\n",
    "                             #.drop('mon')\n",
    "    #                         .coarsen(year=12).mean()\n",
    "                      for expt in expts]\n",
    "    \n",
    "    #print(dsets_mon_mean)\n",
    "    \n",
    "    # align everything with the 4xCO2 experiment\n",
    "    dsets_aligned[k] = xr.concat(dsets_mon_mean, join='outer',\n",
    "                                 dim=expt_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expt_da = xr.DataArray(expts, dims='experiment_id', name='experiment_id',\n",
    "#                         coords={'experiment_id': expts})\n",
    "\n",
    "# dsets_aligned = {}\n",
    "\n",
    "# for k, v in tqdm(dsets_.items()):\n",
    "#     expt_dsets = v.values()\n",
    "#     if any([d is None for d in expt_dsets]):\n",
    "#         print(f\"Missing experiment for {k}\")\n",
    "#         continue\n",
    "    \n",
    "#     for ds in expt_dsets:\n",
    "#         #ds.coords['year'] = ds.time.dt.year\n",
    "#         #ds.coords['month']=ds.time.dt.month\n",
    "#         ds.coords['rawmonth']=ds.time.dt.month+(ds.time.dt.year-1850)*12\n",
    "#         #print(ds.coords)\n",
    "#     # workaround for\n",
    "#     # https://github.com/pydata/xarray/issues/2237#issuecomment-620961663\n",
    "#     dsets_mon_mean = [v[expt].pipe(global_mean)\n",
    "#                              .swap_dims({'time': 'rawmonth'})\n",
    "#                              .drop('time')\n",
    "#                              #.drop('mon')\n",
    "#     #                         .coarsen(year=12).mean()\n",
    "#                       for expt in expts]\n",
    "    \n",
    "#     #print(dsets_mon_mean)\n",
    "    \n",
    "#     # align everything with the 4xCO2 experiment\n",
    "#     dsets_aligned[k] = xr.concat(dsets_mon_mean, join='outer',\n",
    "#                                  dim=expt_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expt_da = xr.DataArray(expts, dims='experiment_id', name='experiment_id',\n",
    "#                        coords={'experiment_id': expts})\n",
    "\n",
    "# dsets_aligned = {}\n",
    "\n",
    "# for k, v in tqdm(dsets_.items()):\n",
    "#     expt_dsets = v.values()\n",
    "#     if any([d is None for d in expt_dsets]):\n",
    "#         print(f\"Missing experiment for {k}\")\n",
    "#         continue\n",
    "    \n",
    "#     for ds in expt_dsets:\n",
    "#         ds.coords['year'] = ds.time.dt.year\n",
    "        \n",
    "#     # workaround for\n",
    "#     # https://github.com/pydata/xarray/issues/2237#issuecomment-620961663\n",
    "#     dsets_ann_mean = [v[expt].pipe(global_mean)\n",
    "#                              .swap_dims({'time': 'year'})\n",
    "#                              .drop('time')\n",
    "#                              .coarsen(year=12).mean()\n",
    "#                       for expt in expts]\n",
    "    \n",
    "#     # align everything with the 4xCO2 experiment\n",
    "#     dsets_aligned[k] = xr.concat(dsets_ann_mean, join='outer',\n",
    "#                                  dim=expt_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with progress.ProgressBar():\n",
    "    dsets_aligned_ = dask.compute(dsets_aligned)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = list(dsets_aligned_.keys())\n",
    "source_da = xr.DataArray(source_ids, dims='source_id', name='source_id',\n",
    "                         coords={'source_id': source_ids})\n",
    "\n",
    "big_ds = xr.concat([ds.reset_coords(drop=True)\n",
    "                    for ds in dsets_aligned_.values()],\n",
    "                    dim=source_da)\n",
    "\n",
    "big_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = big_ds.sel(year=slice(1900, 2100)).to_dataframe().reset_index()\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df_all,\n",
    "            x=\"year\", y=\"tas\", hue='experiment_id',\n",
    "            kind=\"line\", ci=\"sd\", aspect=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.shape)\n",
    "df_by_exp = df_all.groupby('experiment_id')\n",
    "\n",
    "tas_exp = []\n",
    "for name, group in df_by_exp:\n",
    "    group_mon = group.groupby('rawmonth')\n",
    "    tas = np.empty((13,251))\n",
    "    tas[0,:]=np.arange(1850,2101)\n",
    "    month = []\n",
    "    year = []\n",
    "    for mon, mongroup in group_mon:\n",
    "        if mon>251:\n",
    "            break\n",
    "        montemp = np.nanmean(mongroup['tas'])\n",
    "        i_month = int(mon%12)\n",
    "        i_year = int(np.floor(mon/12))\n",
    "        tas[i_month,i_year] = montemp\n",
    "    #print(np.count_nonzero(tas))\n",
    "    #print(np.count_nonzero(np.isnan(tas)))\n",
    "    tas_exp.append(tas)\n",
    "    #years = (np.asarray(months)/12)+1850\n",
    "    #plt.plot(years,avg_temps,label=name,alpha=0.6)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_all.shape)\n",
    "# df_by_exp = df_all.groupby('experiment_id')\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# for name, group in df_by_exp:\n",
    "#     group_mon = group.groupby('rawmonth')\n",
    "#     avg_temps = []\n",
    "#     months = []\n",
    "#     for mon, mongroup in group_mon:\n",
    "#         montemp = np.nanmean(mongroup['tas'])\n",
    "#         avg_temps.append(montemp)\n",
    "#         months.append(mon)\n",
    "#     temps = np.array(group['tas'])\n",
    "#     print(temps.shape)\n",
    "#     print(group.shape)\n",
    "#     years = (np.asarray(months)/12)+1850\n",
    "#     plt.plot(years,avg_temps,label=name,alpha=0.6)\n",
    "#     #plt.show()\n",
    "# #plt.xlim(2000,2020)\n",
    "# #plt.ylim(270,296)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['year'].shape)\n",
    "#years = np.array(df_all['year'])\n",
    "#print(years.shape)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(years,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "for name, group in df_by_exp:\n",
    "    for \n",
    "    plt.plot(group['year'],label=name)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cicoes39",
   "language": "python",
   "name": "cicoes39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
